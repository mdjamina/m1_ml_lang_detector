{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdjamina/m1_ml_lang_detector/blob/main/ML_lang_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsWqzNezu3vU"
      },
      "source": [
        "# Corpus\n",
        "[Tatoeba](https://tatoeba.org/fr/downloads\n",
        ") est une collection de phrases et de traductions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9dop-NpvqVh"
      },
      "source": [
        "Extraction de l'archive téléchargée "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPzTKS9UWwNg",
        "outputId": "7463ffa9-86a4-4e1b-9cee-fe4ae678bab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./data/data.zip\n",
            "warning [./data/data.zip]:  zipfile claims to be last disk of a multi-part archive;\n",
            "  attempting to process anyway, assuming all parts have been concatenated\n",
            "  together in order.  Expect \"errors\" and warnings...true multi-part support\n",
            "  doesn't exist yet (coming soon).\n",
            "file #1:  bad zipfile offset (local header sig):  4\n"
          ]
        }
      ],
      "source": [
        "!unzip ./data/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G86sykMcXWUw"
      },
      "source": [
        "## Chargement du corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "4oMo0Uvp0wek",
        "outputId": "23cbc4d2-b878-4e65-8a62-54b2304fca1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>lang</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>我們試試看！</td>\n",
              "      <td>zho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>我该去睡觉了。</td>\n",
              "      <td>zho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>你在干什麼啊？</td>\n",
              "      <td>zho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>這是什麼啊？</td>\n",
              "      <td>zho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>今天是６月１８号，也是Muiriel的生日！</td>\n",
              "      <td>zho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10262652</th>\n",
              "      <td>Utálom a melóm!</td>\n",
              "      <td>hun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10262653</th>\n",
              "      <td>Ich habe den Ersatzschlüssel verloren.</td>\n",
              "      <td>deu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10262654</th>\n",
              "      <td>Mibe' fogadjunk?</td>\n",
              "      <td>hun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10262655</th>\n",
              "      <td>Utálok itt lenni!</td>\n",
              "      <td>hun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10262656</th>\n",
              "      <td>I don't care about the household.</td>\n",
              "      <td>eng</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8961150 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         content lang\n",
              "0                                         我們試試看！  zho\n",
              "1                                        我该去睡觉了。  zho\n",
              "2                                        你在干什麼啊？  zho\n",
              "3                                         這是什麼啊？  zho\n",
              "4                         今天是６月１８号，也是Muiriel的生日！  zho\n",
              "...                                          ...  ...\n",
              "10262652                         Utálom a melóm!  hun\n",
              "10262653  Ich habe den Ersatzschlüssel verloren.  deu\n",
              "10262654                        Mibe' fogadjunk?  hun\n",
              "10262655                       Utálok itt lenni!  hun\n",
              "10262656       I don't care about the household.  eng\n",
              "\n",
              "[8961150 rows x 2 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_pickle(\"./data/data.pkl\") \n",
        "\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIiE3aUbXarg"
      },
      "source": [
        "# pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btFasJzVxuFv"
      },
      "source": [
        "## TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP19OAAt4iM0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3WwvVw8Yrxqg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['content'], data['lang'], test_size=0.33, train_size=0.1, random_state=1) \n",
        "# ramdom_state = meme corpus (meme decoupage, decouper en 2 train et test le corpus, car on a besoin de faire les tests)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ16poLjqJ2Q",
        "outputId": "396fa427-1ccf-42e4-8bdc-18537563ab05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "eng    157100\n",
              "rus     90726\n",
              "ita     80533\n",
              "tur     72168\n",
              "ber     58763\n",
              "deu     58278\n",
              "kab     51139\n",
              "fra     49837\n",
              "por     39536\n",
              "spa     36408\n",
              "hun     35480\n",
              "jpn     21911\n",
              "heb     19698\n",
              "ukr     17565\n",
              "nld     15472\n",
              "fin     13775\n",
              "pol     11538\n",
              "zho      8451\n",
              "mkd      7728\n",
              "ces      6259\n",
              "dan      5312\n",
              "hbs      5188\n",
              "swe      4552\n",
              "ara      4170\n",
              "lat      4159\n",
              "ell      3362\n",
              "ron      2723\n",
              "fas      2511\n",
              "bul      2463\n",
              "vie      2137\n",
              "slk      1607\n",
              "nor      1530\n",
              "hin      1429\n",
              "kor       906\n",
              "tha       484\n",
              "est       389\n",
              "lav       287\n",
              "gle       273\n",
              "hye       216\n",
              "swa        52\n",
              "Name: lang, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHk7C7h8Xfok"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "def ngram_2c(text):\n",
        "  #text = text.replace(' ','-')\n",
        "  return [re.sub('[ ]?','',i+j) for (i,j) in zip(*[text[i:] for i in range(2)])]\n",
        "  #ng = [re.sub('[ ]?','',i+j+k) for (i,j,k) in zip(*[text[i:] for i in range(3)])]\n",
        "  #ng = [i+j+k+m for (i,j,k,m) in zip(*[text[i:] for i in range(4)]) if j!=' ' or k!=' ']\n",
        "  #for (l,m) in zip(*[text[i:] for i in range(2)]):\n",
        "   # gram=remove_punctuation(l+m)\n",
        "\n",
        "\n",
        "import re\n",
        "def to_char(text):\n",
        "  #text = text.replace(' ','-')\n",
        "  return [c for c in text if c not in ' \\t\\n']\n",
        "  #ng = [re.sub('[ ]?','',i+j+k) for (i,j,k) in zip(*[text[i:] for i in range(3)])]\n",
        "  #ng = [i+j+k+m for (i,j,k,m) in zip(*[text[i:] for i in range(4)]) if j!=' ' or k!=' ']\n",
        "  #for (l,m) in zip(*[text[i:] for i in range(2)]):\n",
        "   # gram=remove_punctuation(l+m)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "to_char('un test de text 그러나 주로 개인적인 용도로 이용되는 위키도 있는데, 이를 개인 위키라고 한다')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GmSw3tCJKvgB"
      },
      "outputs": [],
      "source": [
        "from joblib import Memory\n",
        "from shutil import rmtree\n",
        "\n",
        "# Create a temporary folder to store the transformers of the pipeline\n",
        "mem = Memory(location=\"/tmp/cachedir\", verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(896115, 108154)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer(tokenizer=to_char, ngram_range=(1,2))\n",
        "\n",
        "x_train_counts = count_vect.fit_transform(x_train)\n",
        "x_train_counts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_counts\n",
        "#278559"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoSM-Nu4VxL3",
        "outputId": "10cdea09-4eb4-4a8a-c09e-9d503a1638da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] ... (step 1 of 2) Processing TfidfVectorizer, total=  15.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amina/.local/lib/python3.9/site-packages/sklearn/pipeline.py:348: UserWarning: Persisting input arguments took 3.40s to run.\n",
            "If this happens often in your code, it can cause performance problems \n",
            "(results will be correct in all cases). \n",
            "The reason for this is probably some large input arguments for a wrapped\n",
            " function (e.g. large strings).\n",
            "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
            " example so that they can fix the problem.\n",
            "  X, fitted_transformer = fit_transform_one_cached(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Pipeline] ......... (step 2 of 2) Processing LinearSVC, total= 1.4min\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(memory=Memory(location=/tmp/cachedir/joblib),\n",
              "         steps=[('TfidfVectorizer',\n",
              "                 TfidfVectorizer(ngram_range=(1, 2),\n",
              "                                 tokenizer=<function to_char at 0x7f1701ca1700>)),\n",
              "                ('LinearSVC', LinearSVC())],\n",
              "         verbose=True)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "model = Pipeline([('TfidfVectorizer', TfidfVectorizer(tokenizer=to_char, ngram_range=(1,2))),\n",
        "                     ('LinearSVC', LinearSVC()),],verbose=True,memory=mem)\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train)  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(108086,)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model[0].get_feature_names_out().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2Yt5OcI1Y2zy"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4uJplem8Wket"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 13733     11      0 ...      0      0      0]\n",
            " [     0 160373      0 ...      0      0      0]\n",
            " [     0      0   5154 ...    277      0      0]\n",
            " ...\n",
            " [     0      0     66 ...  53881      0      0]\n",
            " [     0      1      0 ...      0   6901      0]\n",
            " [     0      0      0 ...      0      0  28047]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.confusion_matrix(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylR3yrFlW0ks",
        "outputId": "06dbd96f-5e3c-4b90-af36-40963a94f1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ara       0.99      0.99      0.99     13846\n",
            "         ber       0.80      0.82      0.81    194880\n",
            "         bul       0.92      0.64      0.76      8016\n",
            "         ces       0.94      0.94      0.94     20731\n",
            "         dan       0.82      0.83      0.82     17825\n",
            "         deu       0.98      0.98      0.98    191456\n",
            "         ell       1.00      1.00      1.00     11611\n",
            "         eng       0.98      0.99      0.98    518113\n",
            "         est       0.93      0.50      0.65      1226\n",
            "         fas       0.99      0.99      0.99      8191\n",
            "         fin       0.98      0.97      0.97     45895\n",
            "         fra       0.97      0.97      0.97    164772\n",
            "         gle       0.98      0.85      0.91       861\n",
            "         hbs       0.91      0.82      0.86     16937\n",
            "         heb       1.00      1.00      1.00     65492\n",
            "         hin       1.00      1.00      1.00      4706\n",
            "         hun       0.98      0.99      0.99    117260\n",
            "         hye       0.99      1.00      0.99       764\n",
            "         ita       0.95      0.98      0.97    264916\n",
            "         jpn       1.00      1.00      1.00     72291\n",
            "         kab       0.79      0.77      0.78    169724\n",
            "         kor       1.00      1.00      1.00      3017\n",
            "         lat       0.88      0.80      0.84     13463\n",
            "         lav       0.95      0.91      0.93      1042\n",
            "         mkd       0.86      0.89      0.88     25600\n",
            "         nld       0.95      0.92      0.94     50980\n",
            "         nor       0.76      0.36      0.49      5350\n",
            "         pol       0.99      0.99      0.99     38210\n",
            "         por       0.96      0.94      0.95    129971\n",
            "         ron       0.98      0.89      0.93      8781\n",
            "         rus       0.97      0.99      0.98    297386\n",
            "         slk       0.89      0.67      0.76      5527\n",
            "         spa       0.94      0.93      0.94    121437\n",
            "         swa       0.77      0.32      0.45       206\n",
            "         swe       0.92      0.88      0.90     15274\n",
            "         tha       0.62      1.00      0.76      1490\n",
            "         tur       0.99      0.99      0.99    236566\n",
            "         ukr       0.97      0.92      0.94     58388\n",
            "         vie       1.00      1.00      1.00      6923\n",
            "         zho       1.00      1.00      1.00     28056\n",
            "\n",
            "    accuracy                           0.95   2957180\n",
            "   macro avg       0.93      0.89      0.90   2957180\n",
            "weighted avg       0.95      0.95      0.95   2957180\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#from sklearn import metrics\n",
        "print(metrics.classification_report(y_test,predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-gwB4OKW4Ye",
        "outputId": "5614de4f-144e-4dc2-e5d2-9e61d70b09be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.841213926781596"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics.accuracy_score(y_test,predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OuCtJl8CW9Gz",
        "outputId": "6600c454-9988-4e78-e045-5b0a1ad27dcb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'kor'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(['그러나 주로 개인적인 용도로 이용되는 위키도 있는데, 이를 개인 위키라고 한다. bonjour'])[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sQxJ7CURiwAM",
        "outputId": "7d2fc5cc-9643-429f-8434-7efee06e9b38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'heb'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(['ויקי יכולה להיות שיטה טובה לשיתוף ידע בקהילות שפועלות באמצעות האינטרנט או בתוךיות. היא חלופה'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FjgXnAGHiwjm",
        "outputId": "17c11cf8-e656-4fab-e6b0-8a4f2ed16c5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'deu'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(['einsetzt. Zudem nutzen auch viele '])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vRB_PiDWjZf6",
        "outputId": "2ddf6983-963b-4a4e-d106-c3f1ee520813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ara'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(['الكرام بتحويل الكتابة العربي الى كتابة مفهومة من قبل اغلب برامج التصميم مثل الفوتوشوب و الافترايفكتس و البريمير و الافد ميدا كومبوزر و السموك و برامج اخرى'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6qVsUhPhkES_",
        "outputId": "1fd4f36e-96a9-4496-948a-63424a3de146"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hin'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(['से प्रत्येक एक विशिष्ट भाषा से संबंधित है। विकिपीडिया के अलावा, सार्वजनिक और निजी दोनों उपयोग में सैकड़ों हजारों अ'])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCjBWMXbGhv6"
      },
      "source": [
        "# Model persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdaB3qyFGMz1",
        "outputId": "a660e408-d7e6-4f78-f964-b413a84241f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['data/lang_detector.joblib']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from joblib import dump\n",
        "dump(model, 'data/lang_detector.joblib') "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMw6TSkr2UeNLxm29k70BP8",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ML_lang_detector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
